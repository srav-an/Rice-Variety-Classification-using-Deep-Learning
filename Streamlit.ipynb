{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38373,"status":"ok","timestamp":1656222400368,"user":{"displayName":"Nakendraprasath K","userId":"17028123091009269030"},"user_tz":-330},"id":"HxGmCmceT4Vh","outputId":"e0c0eb27-38e3-46f1-ea3c-824318b7726d"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K\u001b[?25h/tools/node/bin/lt -> /tools/node/lib/node_modules/localtunnel/bin/lt.js\n","+ localtunnel@2.0.2\n","added 22 packages from 22 contributors in 1.974s\n","\u001b[K     |████████████████████████████████| 9.1 MB 4.9 MB/s \n","\u001b[K     |████████████████████████████████| 232 kB 34.2 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 35.4 MB/s \n","\u001b[K     |████████████████████████████████| 4.3 MB 30.7 MB/s \n","\u001b[K     |████████████████████████████████| 164 kB 36.7 MB/s \n","\u001b[K     |████████████████████████████████| 111 kB 11.0 MB/s \n","\u001b[K     |████████████████████████████████| 78 kB 4.0 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 941 kB/s \n","\u001b[K     |████████████████████████████████| 133 kB 35.0 MB/s \n","\u001b[K     |████████████████████████████████| 428 kB 33.8 MB/s \n","\u001b[K     |████████████████████████████████| 132 kB 14.8 MB/s \n","\u001b[K     |████████████████████████████████| 793 kB 37.0 MB/s \n","\u001b[K     |████████████████████████████████| 381 kB 37.2 MB/s \n","\u001b[K     |████████████████████████████████| 51 kB 3.7 MB/s \n","\u001b[?25h  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","nbclient 0.6.4 requires traitlets>=5.2.2, but you have traitlets 5.1.1 which is incompatible.\n","jupyter-console 5.2.0 requires prompt-toolkit<2.0.0,>=1.0.0, but you have prompt-toolkit 3.0.29 which is incompatible.\n","google-colab 1.0.0 requires ipykernel~=4.10, but you have ipykernel 6.15.0 which is incompatible.\n","google-colab 1.0.0 requires ipython~=5.5.0, but you have ipython 7.34.0 which is incompatible.\n","google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\u001b[0m\n"]}],"source":["!npm install -g localtunnel\n","!pip install streamlit -q"]},{"cell_type":"code","source":["!pip install ipykernel --upgrade\n","!pip install ipython --upgrade\n","!pip install torado --upgrade"],"metadata":{"id":"KUacEHz6jZQv"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":565,"status":"ok","timestamp":1656222575625,"user":{"displayName":"Nakendraprasath K","userId":"17028123091009269030"},"user_tz":-330},"id":"t3ax2ZlwT8VG","outputId":"ee4aadea-4e0e-4e55-ff61-ac026254b041"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting app.py\n"]}],"source":["%%writefile app.py\n","import streamlit as st\n","import pickle\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import plotly.express as px\n","from PIL import Image\n","\n","from sklearn import metrics\n","from sklearn import preprocessing\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.decomposition import PCA\n","from sklearn.metrics import accuracy_score\n","\n","from keras.models import load_model\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.layers import Flatten, Dense, Dropout, BatchNormalization\n","from tensorflow.keras.optimizers import Adamax, Adam, SGD, Adagrad ,RMSprop\n","\n","new_title = '<h1 style=\"font-family:sans-serif; color:NAVY; font-size: 50px; align =\"right\">Classification of rice varieties using numeric and image data by Deep Neural Network techniques</h1>'\n","st.markdown(new_title, unsafe_allow_html=True)\n","\n","st.sidebar.subheader(\"SELECT A MODEL OF YOUR CHOICE\")\n","x = st.sidebar.selectbox(label = 'MODEL',options = [\"ANN\", \"DNN\", \"VGG16\"])\n","\n","st.write(\"\\n\\n\\n\\n\\n\")\n","m = '<h2 style=\"font-family:sans-serif; color: BROWN; font-size: 30px; align =\"right\">INTRODUCTION</h2>'\n","st.markdown(m , unsafe_allow_html = True)\n","st.markdown(\"The goal of this research is to create a non-destructive model that uses images of rice varieties to improve classification performance and to extract various properties of grain products using an image processing system. Then, to identify raw photos, build deep learning models, compare them, and evaluate the findings.\\n \")\n","\n","m2 = '<h2 style=\"font-family:sans-serif; color: BROWN; font-size: 30px; align =\"right\">SAMPLE DATASET</h2>'\n","st.markdown(m2 , unsafe_allow_html = True)\n","imgsd = Image.open(\"sampledataset.png\")\n","st.image(imgsd)\n","st.markdown(\"The dataset includes 5 different rice varities namely Arborio, Basmati, Ipsala, Jasmine and Karacadag\")\n","st.markdown(\"Each variety contains 15,000 images. The whole dataset contains 75,000 images of sample data\")\n","\n","m2 = '<h2 style=\"font-family:sans-serif; color: BROWN; font-size: 30px; align =\"right\">DATA PREPROCESSING</h2>'\n","st.markdown(m2 , unsafe_allow_html = True)\n","st.markdown(\"To balance the data, Nan values where removed and then applied Standard Scalar and Principle component analysis\")\n","#imgsd = Image.open(\"dataprep3.png\")\n","#st.image(imgsd)\n","\n","m2 = '<h2 style=\"font-family:sans-serif; color: BLACK; font-size: 20px; align =\"right\">In the project 3 different models were compared namely ANN, DNN, VGG16</h2>'\n","st.markdown(m2 , unsafe_allow_html = True)\n","m2 = '<h2 style=\"font-family:sans-serif; color: BLACK; font-size: 20px; align =\"right\">The proposed model is VGG16</h2>'\n","st.markdown(m2 , unsafe_allow_html = True)\n","\n","df_labels = {\n","    'arborio' : 0,\n","    'basmati' : 1,\n","    'ipsala' : 2,\n","    'jasmine' : 3,\n","    'karacadag': 4\n","}\n","new_key = list(df_labels)\n","\n","if x == \"ANN\":\n","    st.write(\"User Input\")\n","    m3 = '<h2 style=\"font-family:sans-serif; color: BROWN; font-size: 30px; align =\"right\">MODEL DETAILS</h2>'\n","    st.markdown(m3 , unsafe_allow_html = True)\n","    if st.button(\"Click here to see model details\"):\n","        st.write(\"Training Loss:    0.001284547965042293\")\n","        st.write(\"Validation Loss:  0.004056261386722326\")\n","        st.write(\"Train Score:      0.9998332858085632\")\n","        st.write(\"Test Score:       0.999133288860321\")\n","        img1 = Image.open(\"ANNresults.png\")\n","        img2 = Image.open(\"ANN_classreport.png\")\n","        img3 = Image.open(\"ANN_confusion.png\")\n","        st.subheader(\"Model accuracy plots\")\n","        st.image(img1)\n","        st.subheader(\"Confusion Matrix\")\n","        st.image(img3)\n","        st.subheader(\"Classification Report\")\n","        st.image(img2)\n","\n","if x == \"DNN\":\n","    m3 = '<h2 style=\"font-family:sans-serif; color: BROWN; font-size: 30px; align =\"right\">MODEL DETAILS</h2>'\n","    st.markdown(m3 , unsafe_allow_html = True)\n","    if st.button(\"Click here to see model details\"):\n","        st.write(\"Training Loss:    0.005439203232526779\")\n","        st.write(\"Validation Loss:  0.07092532515525818\")\n","        st.write(\"Train Score:      0.9993665814399719\")\n","        st.write(\"Test Score:       0.9989332556724548\")\n","        img1 = Image.open(\"DNNresults.png\")\n","        img2 = Image.open(\"CNN_classification.png\")\n","        img3 = Image.open(\"DNN_confusion.png\")\n","        st.subheader(\"Model accuracy plots\")\n","        st.image(img1)\n","        st.subheader(\"Classification Report\")\n","        st.subheader(\"Confusion Matrix\")\n","        st.image(img3)\n","        st.subheader(\"Classification Report\")\n","        st.image(img2)\n","\n","if x == \"VGG16\":\n","    m3 = '<h2 style=\"font-family:sans-serif; color: BROWN; font-size: 30px; align =\"right\">MODEL DETAILS</h2>'\n","    st.markdown(m3 , unsafe_allow_html = True)\n","    if st.button(\"Click here to see model details\"):\n","        st.write(\"Training Loss: 0.02162024166584015\")\n","        st.write(\"Validation Loss: 0.09527199065065384\")\n","        st.write(\"Train Score: 0.999799943447113\")\n","        st.write(\"Test Score: 0.9989452915256348\")\n","        img1 = Image.open(\"CNNresults.png\")\n","        img2 = Image.open(\"ANN_classreport.png\")\n","        img3 = Image.open(\"ANN_confusion.png\")\n","        st.subheader(\"Model accuracy plots\")\n","        st.image(img1)\n","        st.subheader(\"Classification Report\")\n","        st.subheader(\"Confusion Matrix\")\n","        st.image(img3)\n","        st.subheader(\"Classification Report\")\n","        st.image(img2)\n","\n","m2 = '<h2 style=\"font-family:sans-serif; color: BROWN; font-size: 30px; align =\"right\">PREDICTION:</h2>'\n","st.markdown(m2 , unsafe_allow_html = True)\n","if x == \"ANN\":\n","  uploaded_file = st.file_uploader(\"Upload spreadsheet\", type=[\"csv\", \"xlsx\"])\n","  if uploaded_file:\n","    # Check MIME type of the uploaded file\n","    if uploaded_file.type == \"text/csv\":\n","        df = pd.read_csv(uploaded_file)\n","    else:\n","        df = pd.read_excel(uploaded_file)\n","    label_encoder = preprocessing.LabelEncoder()\n","    df['CLASS']= label_encoder.fit_transform(df['CLASS'])\n","    df = df.dropna()\n","    X=df.drop(['CLASS'],axis=1)\n","    y=df.CLASS\n","    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    pca = PCA().fit(X_train)\n","    X_train = pca.transform(X_train)\n","    X_test = pca.transform(X_test)\n","    model = load_model('/content/drive/MyDrive/Mini prj/Code/ANN_model.h5')\n","    prob = model.predict(X_test)\n","    labels = prob.argmax(axis=1)\n","    st.write(\"Your accuracy for the given dataset is: \")\n","    st.write(accuracy_score(y_test,labels))\n","    score_mse_test = model.evaluate(X_test, y_test)\n","    st.write('Test Score:', score_mse_test[1])\n","    score_mse_train = model.evaluate(X_train, y_train)\n","    st.write('Train Score:', score_mse_train[1])\n","\n","if x == \"DNN\":\n","  uploaded_file = st.file_uploader(\"Upload spreadsheet\", type=[\"csv\", \"xlsx\"])\n","  if uploaded_file:\n","    # Check MIME type of the uploaded file\n","    if uploaded_file.type == \"text/csv\":\n","        df = pd.read_csv(uploaded_file)\n","    else:\n","        df = pd.read_excel(uploaded_file)\n","    label_encoder = preprocessing.LabelEncoder()\n","    df['CLASS']= label_encoder.fit_transform(df['CLASS'])\n","    df = df.dropna()\n","    X=df.drop(['CLASS'],axis=1)\n","    y=df.CLASS\n","    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)\n","    scaler = StandardScaler()\n","    X_train = scaler.fit_transform(X_train)\n","    X_test = scaler.transform(X_test)\n","    pca = PCA().fit(X_train)\n","    X_train = pca.transform(X_train)\n","    X_test = pca.transform(X_test)\n","    model = load_model('/content/drive/MyDrive/Mini prj/Code/DNN_model.h5')\n","    prob = model.predict(X_test)\n","    labels = prob.argmax(axis=1)\n","    st.write(\"Your accuracy for the given dataset is: \")\n","    st.write(accuracy_score(y_test,labels))\n","    score_mse_test = model.evaluate(X_test, y_test)\n","    st.write('Test Score:', score_mse_test[1])\n","    score_mse_train = model.evaluate(X_train, y_train)\n","    st.write('Train Score:', score_mse_train[1])\n","\n","if x=='VGG16':\n","  img = st.file_uploader(label = \"\")\n","  if st.button(\"Predict\"):\n","        if img is not None:\n","            im = Image.open(img)\n","            im = im.resize((256,256))\n","            pix_val = list(im.getdata())\n","            pix_val_flat = [x for sets in pix_val for x in sets]\n","            Data = np.array(pix_val_flat).reshape(-1,256,256,3)\n","            model3 = load_model(\"my_model.h5\")\n","            ans = model3.predict(Data)[0]\n","            #st.write(\"CONFIDENCE =\",max(ans)*100, \"%\")\n","            st.write(\"Prediction: \")\n","            index = ans.argmax(axis = 0)\n","            st.write(new_key[index])\n","\n","st.sidebar.markdown(\"Developed by: \")\n","st.sidebar.markdown(\"123018040- Jaganath Sankaranarayanan\")\n","st.sidebar.markdown(\"123018062- Nakendraprasath K\")\n","st.sidebar.markdown(\"123018092- Sravan Srinivasan S\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"InP1DP1_UFSE","outputId":"da127e5c-9f07-48e1-8cb3-c83dfc76cd0a"},"outputs":[{"output_type":"stream","name":"stdout","text":["2022-06-26 05:49:37.302 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n","\u001b[K\u001b[?25hnpx: installed 22 in 5.194s\n","\u001b[0m\n","\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n","\u001b[0m\n","\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n","\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.136.235.134:8501\u001b[0m\n","\u001b[0m\n"]}],"source":["!streamlit run app.py & npx localtunnel --port 7000"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4HpcS9rwUW9W"},"outputs":[],"source":["# title, intro, sample data, upload csv or img\n","# sidebar: selection of model\n","# results"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Streamlit.ipynb","provenance":[],"mount_file_id":"1taLjmrCm9t8dPfE0WZDnoGDqb5aaWhGW","authorship_tag":"ABX9TyMaZJZ43fIE68H8v5NEdIfn"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}